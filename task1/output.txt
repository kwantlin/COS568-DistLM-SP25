kw2960@node-0:/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1$ python3 run_glue.py \
  --model_type bert \
  --model_name_or_path bert-base-cased \
  --task_name $TASK_NAME \
  --do_train \
  --do_eval \
  --data_dir $GLUE_DIR/$TASK_NAME \
  --max_seq_length 128 \
  --per_device_train_batch_size 64 \
  --learning_rate 2e-5 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir
03/27/2025 12:54:36 - WARNING - __main__ -   Process rank: -1, device: cpu, distributed training: False, 16-bits training: False
03/27/2025 12:54:36 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/kw2960/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/27/2025 12:54:36 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/27/2025 12:54:36 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/kw2960/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/27/2025 12:54:37 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/kw2960/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
/users/kw2960/.local/lib/python3.10/site-packages/pytorch_transformers/modeling_utils.py:539: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(resolved_archive_file, map_location='cpu')
03/27/2025 12:54:45 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/27/2025 12:54:45 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/27/2025 12:54:45 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=64, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/27/2025 12:54:45 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1/run_glue.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(cached_features_file)
03/27/2025 12:54:47 - INFO - __main__ -   ***** Running training *****
03/27/2025 12:54:47 - INFO - __main__ -     Num examples = 2490
03/27/2025 12:54:47 - INFO - __main__ -     Num Epochs = 3
03/27/2025 12:54:47 - INFO - __main__ -     Instantaneous batch size per device = 64
03/27/2025 12:54:47 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/27/2025 12:54:47 - INFO - __main__ -     Gradient Accumulation steps = 1
03/27/2025 12:54:47 - INFO - __main__ -     Total optimization steps = 117
Epoch:   0%|                                                                                                                                                                            | 0/3 [00:00<?, ?it/s0
3/27/2025 12:54:52 - INFO - __main__ -   Minibatch 0, Loss: 0.769171                                                                                                                   | 0/39 [00:00<?, ?it/s]
/users/kw2960/.local/lib/python3.10/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1642.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
                                                                                                                                                                                                             0
3/27/2025 12:55:04 - INFO - __main__ -   Minibatch 1, Loss: 0.781734                                                                                                           | 1/39 [00:13<08:36, 13.60s/it]
                                                                                                                                                                                                             0
3/27/2025 12:55:14 - INFO - __main__ -   Minibatch 2, Loss: 0.688584                                                                                                           | 2/39 [00:23<07:01, 11.40s/it]
                                                                                                                                                                                                             0
3/27/2025 12:55:24 - INFO - __main__ -   Minibatch 3, Loss: 0.766275                                                                                                           | 3/39 [00:33<06:21, 10.60s/it]
                                                                                                                                                                                                             0
3/27/2025 12:55:33 - INFO - __main__ -   Minibatch 4, Loss: 0.734187                                                                                                           | 4/39 [00:42<05:51, 10.04s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:31<00:00,  8.51s/it]
03/27/2025 13:00:19 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte████████████████████████████| 39/39 [05:31<00:00,  7.92s/it]
/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1/run_glue.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(cached_features_file)
03/27/2025 13:00:19 - INFO - __main__ -   ***** Running evaluation  *****
03/27/2025 13:00:19 - INFO - __main__ -     Num examples = 277
03/27/2025 13:00:19 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.98it/s]
03/27/2025 13:00:31 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.24it/s]
03/27/2025 13:00:31 - INFO - __main__ -     acc = 0.628158844765343
Epoch:  33%|██████████████████████████████████████████████████████▎                                                                                                            | 1/3 [05:43<11:27, 343.59s/it0
3/27/2025 13:00:34 - INFO - __main__ -   Minibatch 0, Loss: 0.664468                                                                                                                   | 0/39 [00:00<?, ?it/s]
                                                                                                                                                                                                             0
3/27/2025 13:00:42 - INFO - __main__ -   Minibatch 1, Loss: 0.675686                                                                                                           | 1/39 [00:07<05:03,  7.99s/it]
                                                                                                                                                                                                             0
3/27/2025 13:00:50 - INFO - __main__ -   Minibatch 2, Loss: 0.678750                                                                                                           | 2/39 [00:16<04:57,  8.04s/it]
                                                                                                                                                                                                             0
3/27/2025 13:00:58 - INFO - __main__ -   Minibatch 3, Loss: 0.638657                                                                                                           | 3/39 [00:24<04:52,  8.12s/it]
                                                                                                                                                                                                             0
3/27/2025 13:01:06 - INFO - __main__ -   Minibatch 4, Loss: 0.645966                                                                                                           | 4/39 [00:32<04:46,  8.18s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:15<00:00,  8.09s/it]
03/27/2025 13:05:46 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte████████████████████████████| 39/39 [05:15<00:00,  7.81s/it]
03/27/2025 13:05:46 - INFO - __main__ -   ***** Running evaluation  *****
03/27/2025 13:05:46 - INFO - __main__ -     Num examples = 277
03/27/2025 13:05:46 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.98it/s]
03/27/2025 13:05:58 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.24it/s]
03/27/2025 13:05:58 - INFO - __main__ -     acc = 0.6498194945848376
Epoch:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 2/3 [11:10<05:34, 334.05s/it0
3/27/2025 13:06:01 - INFO - __main__ -   Minibatch 0, Loss: 0.629196                                                                                                                   | 0/39 [00:00<?, ?it/s]
                                                                                                                                                                                                             0
3/27/2025 13:06:09 - INFO - __main__ -   Minibatch 1, Loss: 0.587645                                                                                                           | 1/39 [00:07<05:03,  7.99s/it]
                                                                                                                                                                                                             0
3/27/2025 13:06:17 - INFO - __main__ -   Minibatch 2, Loss: 0.556609                                                                                                           | 2/39 [00:16<04:58,  8.06s/it]
                                                                                                                                                                                                             0
3/27/2025 13:06:25 - INFO - __main__ -   Minibatch 3, Loss: 0.580096                                                                                                           | 3/39 [00:24<04:49,  8.04s/it]
                                                                                                                                                                                                             0
3/27/2025 13:06:33 - INFO - __main__ -   Minibatch 4, Loss: 0.550949                                                                                                           | 4/39 [00:32<04:42,  8.08s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:13<00:00,  8.03s/it]
03/27/2025 13:11:11 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte████████████████████████████| 39/39 [05:13<00:00,  7.80s/it]
03/27/2025 13:11:11 - INFO - __main__ -   ***** Running evaluation  *****
03/27/2025 13:11:11 - INFO - __main__ -     Num examples = 277
03/27/2025 13:11:11 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.97it/s]
03/27/2025 13:11:23 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.22it/s]
03/27/2025 13:11:23 - INFO - __main__ -     acc = 0.6209386281588448
Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [16:35<00:00, 331.96s/it]
03/27/2025 13:11:23 - INFO - __main__ -    global_step = 117, average loss = 0.6365271215764885
03/27/2025 13:11:23 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/27/2025 13:11:23 - INFO - __main__ -   ***** Running evaluation  *****
03/27/2025 13:11:23 - INFO - __main__ -     Num examples = 277
03/27/2025 13:11:23 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.92it/s]
03/27/2025 13:11:35 - INFO - __main__ -   ***** Eval results  *****
03/27/2025 13:11:35 - INFO - __main__ -     acc = 0.6209386281588448