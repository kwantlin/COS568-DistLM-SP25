kw2960@node-0:/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1$ python3 run_glue.py \
  --model_type bert \
  --model_name_or_path bert-base-cased \
  --task_name $TASK_NAME \
  --do_train \
  --do_eval \
  --data_dir $GLUE_DIR/$TASK_NAME \
  --max_seq_length 128 \
  --per_device_train_batch_size 64 \
  --learning_rate 2e-5 \
  --num_train_epochs 3 \
  --output_dir /tmp/$TASK_NAME/ \
  --overwrite_output_dir
03/28/2025 07:47:05 - WARNING - __main__ -   Process rank: -1, device: cpu, distributed training: False, 16-bits training: False
03/28/2025 07:47:05 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/kw2960/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/28/2025 07:47:05 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/28/2025 07:47:05 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/kw2960/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/28/2025 07:47:05 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/kw2960/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
/users/kw2960/.local/lib/python3.10/site-packages/pytorch_transformers/modeling_utils.py:539: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(resolved_archive_file, map_location='cpu')
03/28/2025 07:47:14 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/28/2025 07:47:14 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/28/2025 07:47:14 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=64, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/28/2025 07:47:14 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1/run_glue.py:266: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(cached_features_file)
03/28/2025 07:47:16 - INFO - __main__ -   ***** Running training *****
03/28/2025 07:47:16 - INFO - __main__ -     Num examples = 2490
03/28/2025 07:47:16 - INFO - __main__ -     Num Epochs = 3
03/28/2025 07:47:16 - INFO - __main__ -     Instantaneous batch size per device = 64
03/28/2025 07:47:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/28/2025 07:47:16 - INFO - __main__ -     Gradient Accumulation steps = 1
03/28/2025 07:47:16 - INFO - __main__ -     Total optimization steps = 117
Epoch:   0%|                                                                                                                                                                            | 0/3 [00:00<?, ?it/s0
3/28/2025 07:47:21 - INFO - __main__ -   Minibatch 0, Loss: 0.769171                                                                                                                   | 0/39 [00:00<?, ?it/s]
/users/kw2960/.local/lib/python3.10/site-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:
        add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
        add_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1642.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
                                                                                                                                                                                                             0
3/28/2025 07:47:33 - INFO - __main__ -   Minibatch 1, Loss: 0.781734                                                                                                           | 1/39 [00:13<08:43, 13.78s/it]
                                                                                                                                                                                                             0
3/28/2025 07:47:44 - INFO - __main__ -   Minibatch 2, Loss: 0.688584                                                                                                           | 2/39 [00:23<07:09, 11.61s/it]
                                                                                                                                                                                                             0
3/28/2025 07:47:53 - INFO - __main__ -   Minibatch 3, Loss: 0.766275                                                                                                           | 3/39 [00:34<06:36, 11.02s/it]
                                                                                                                                                                                                             0
3/28/2025 07:48:02 - INFO - __main__ -   Minibatch 4, Loss: 0.734187                                                                                                           | 4/39 [00:43<06:00, 10.29s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:36<00:00,  8.62s/it]
03/28/2025 07:52:52 - INFO - __main__ -   Average time per iteration (excluding first): 8.4815 seconds████████████████████████████████████████████████████████████████████████| 39/39 [05:36<00:00,  7.99s/it]
03/28/2025 07:52:52 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
/proj/cos568proj2-PG0/groups/kw2960/COS568-DistLM-SP25/task1/run_glue.py:266: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  features = torch.load(cached_features_file)
03/28/2025 07:52:52 - INFO - __main__ -   ***** Running evaluation  *****
03/28/2025 07:52:52 - INFO - __main__ -     Num examples = 277
03/28/2025 07:52:52 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.98it/s]
03/28/2025 07:53:04 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.24it/s]
03/28/2025 07:53:04 - INFO - __main__ -     acc = 0.628158844765343
Epoch:  33%|██████████████████████████████████████████████████████▎                                                                                                            | 1/3 [05:48<11:36, 348.01s/it0
3/28/2025 07:53:07 - INFO - __main__ -   Minibatch 0, Loss: 0.664468                                                                                                                   | 0/39 [00:00<?, ?it/s]
                                                                                                                                                                                                             0
3/28/2025 07:53:15 - INFO - __main__ -   Minibatch 1, Loss: 0.675686                                                                                                           | 1/39 [00:08<05:08,  8.12s/it]
                                                                                                                                                                                                             0
3/28/2025 07:53:23 - INFO - __main__ -   Minibatch 2, Loss: 0.678750                                                                                                           | 2/39 [00:16<05:00,  8.11s/it]
                                                                                                                                                                                                             0
3/28/2025 07:53:31 - INFO - __main__ -   Minibatch 3, Loss: 0.638657                                                                                                           | 3/39 [00:24<04:54,  8.19s/it]
                                                                                                                                                                                                             0
3/28/2025 07:53:39 - INFO - __main__ -   Minibatch 4, Loss: 0.645966                                                                                                           | 4/39 [00:32<04:46,  8.18s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:16<00:00,  8.12s/it]
03/28/2025 07:58:21 - INFO - __main__ -   Average time per iteration (excluding first): 8.1193 seconds████████████████████████████████████████████████████████████████████████| 39/39 [05:16<00:00,  7.82s/it]
03/28/2025 07:58:21 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/28/2025 07:58:21 - INFO - __main__ -   ***** Running evaluation  *****
03/28/2025 07:58:21 - INFO - __main__ -     Num examples = 277
03/28/2025 07:58:21 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.95it/s]
03/28/2025 07:58:32 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.21it/s]
03/28/2025 07:58:32 - INFO - __main__ -     acc = 0.6498194945848376
Epoch:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 2/3 [11:16<05:36, 336.66s/it0
3/28/2025 07:58:35 - INFO - __main__ -   Minibatch 0, Loss: 0.629196                                                                                                                   | 0/39 [00:00<?, ?it/s]
                                                                                                                                                                                                             0
3/28/2025 07:58:43 - INFO - __main__ -   Minibatch 1, Loss: 0.587645                                                                                                           | 1/39 [00:08<05:04,  8.01s/it]
                                                                                                                                                                                                             0
3/28/2025 07:58:51 - INFO - __main__ -   Minibatch 2, Loss: 0.556609                                                                                                           | 2/39 [00:16<04:58,  8.08s/it]
                                                                                                                                                                                                             0
3/28/2025 07:58:59 - INFO - __main__ -   Minibatch 3, Loss: 0.580096                                                                                                           | 3/39 [00:24<04:49,  8.05s/it]
                                                                                                                                                                                                             0
3/28/2025 07:59:08 - INFO - __main__ -   Minibatch 4, Loss: 0.550949                                                                                                           | 4/39 [00:32<04:42,  8.06s/it]
Iteration: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [05:14<00:00,  8.06s/it]
03/28/2025 08:03:47 - INFO - __main__ -   Average time per iteration (excluding first): 8.0551 seconds████████████████████████████████████████████████████████████████████████| 39/39 [05:14<00:00,  7.79s/it]
03/28/2025 08:03:47 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/28/2025 08:03:47 - INFO - __main__ -   ***** Running evaluation  *****
03/28/2025 08:03:47 - INFO - __main__ -     Num examples = 277
03/28/2025 08:03:47 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  2.98it/s]
03/28/2025 08:03:58 - INFO - __main__ -   ***** Eval results  *****███████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:11<00:00,  3.25it/s]
03/28/2025 08:03:58 - INFO - __main__ -     acc = 0.6209386281588448
Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [16:42<00:00, 334.24s/it]
03/28/2025 08:03:58 - INFO - __main__ -    global_step = 117, average loss = 0.6365272196439596
03/28/2025 08:03:58 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/28/2025 08:03:59 - INFO - __main__ -   ***** Running evaluation  *****
03/28/2025 08:03:59 - INFO - __main__ -     Num examples = 277
03/28/2025 08:03:59 - INFO - __main__ -     Batch size = 8
Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [00:12<00:00,  2.87it/s]
03/28/2025 08:04:11 - INFO - __main__ -   ***** Eval results  *****
03/28/2025 08:04:11 - INFO - __main__ -     acc = 0.6209386281588448